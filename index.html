<!DOCTYPE html>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
  <head>
    <title>Gu Weiwei</title>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, user-scalable=no"
    />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript
      ><link rel="stylesheet" href="assets/css/noscript.css"
    /></noscript>
  </head>
  <body class="is-preload">
    <!-- Wrapper -->
    <div id="wrapper">
      <!-- Header -->
      <header id="header" class="alt">
        <a href="index.html" class="logo"
          ><strong>BUCT</strong> <span>Gu Weiwei</span></a
        >
        <nav>
          <a href="#menu">Menu</a>
        </nav>
      </header>

      <!-- Menu -->
      <nav id="menu">
        <ul class="links">
          <li><a href="index.html">HOME</a></li>
          <li><a href="publications.html">PUBLICATIONS</a></li>
          <li><a href="students.html">STUDENTS</a></li>
          <li><a href="fund.html">FUNDING</a></li>
        </ul>
      </nav>

      <!-- Banner -->
      <section id="banner" class="major">
        <div class="inner">
          <div class="row">
            <div class="col-3 col-12-medium" style="text-align: center">
              <img
                src="./images/guweiwei.jpg"
                alt=""
                style="width: 100%; height: auto"
              />
            </div>
            <div class="col-9 col-12-medium">
              <header class="major">
                <h1>Gu Weiwei</h1>
              </header>
              <div class="content">
                <p style="text-transform: none; font-size: 1.2rem">
                  I am an associate professor at Beijing University of Chemical
                  Technology. My research focuses on graph convolutional neural
                  networks, multi-source heterogeneous data mining, and the
                  analysis of network robustness by integrating representation
                  learning with reinforcement learning. My relevant works have
                  been published in journals such as Nature Communications,
                  Social Networks, and Journal of Social Computing. I have also
                  presided over one Postdoctoral Science Foundation General
                  Project and currently serve as an editor for the Journal of
                  Social Computing.
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- Main -->
      <div id="main">
        <section id="two">
          <div class="inner">
            <header class="major">
              <h2>Main Publications</h2>
            </header>
            <ul class="alt">
              <span class="image left">
                <img
                  src="./images/paperNMI.jpg"
                  alt=""
                  style="background-color: black"
                />
              </span>
              <a href="" target="_blank" rel="noopener noreferrer">
                <h3 style="text-decoration: underline">
                  Deep-learning-aided dismantling of interdependent networks.
                  <em>Nature Machine Intelligence.</em>
                </h3>
              </a>

              <h5>
                <p>
                  Weiwei Gu, Chen Yang, Lei Li, Jinqiang Hou, Filippo Radicchi
                </p>
              </h5>
              <p>
                Identifying the minimal set of nodes whose removal breaks a
                complex network apart, also referred as the network dismantling
                problem, is a highly non-trivial task with applications in
                multiple domains. Whereas network dismantling has been
                extensively studied over the past decade, research has primarily
                focused on the optimization problem for single-layer networks,
                neglecting that many, if not all, real networks display multiple
                layers of interdependent interactions. In such networks, the
                optimization problem is fundamentally different as the effect of
                removing nodes propagates within and across layers in a way that
                can not be predicted using a single-layer perspective. Here, we
                propose a dismantling algorithm named MultiDismantler, which
                leverages multiplex network representation and deep
                reinforcement learning to optimally dismantle multi-layer
                interdependent networks. MultiDismantler is trained on small
                synthetic graphs; when applied to large, either real or
                synthetic networks, it displays exceptional dismantling
                performance, clearly outperforming all existing benchmark
                algorithms. We show that MultiDismantler is effective in guiding
                strategies for the containment of diseases in social networks
                characterized by multiple layers of social interactions. Also,
                we show that MultiDismantler is useful in the design of
                protocols aimed at delaying the onset of cascading failures in
                interdependent critical infrastructures.
              </p>
              <!-- <ul class="actions">
                <li>
                  <a
                    href="https://www.nature.com/articles/s41467-021-23795-5.pdf"
                    class="button"
                  >
                    Download
                  </a>
                </li>
              </ul> -->
            </ul>
            <ul class="alt">
              <span class="image left">
                <img
                  src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-021-23795-5/MediaObjects/41467_2021_23795_Fig1_HTML.png?as=webp"
                  alt=""
                  style="background-color: black"
                />
              </span>
              <a
                href="https://www.nature.com/articles/s41467-021-23795-5"
                target="_blank"
                rel="noopener noreferrer"
              >
                <h3 style="text-decoration: underline">
                  Principled approach to the selection of the embedding
                  dimension of networks. <em>Nature Communications.</em>
                </h3>
              </a>

              <h5>
                <p>Weiwei Gu, Aditya Tandon, Yong-Yeol Ahn, Filippo Radicchi</p>
              </h5>
              <p>
                Network embedding is a general-purpose machine learning
                technique that encodes network structure in vector spaces with
                tunable dimension. Choosing an appropriate embedding dimension –
                small enough to be efficient and large enough to be effective –
                is challenging but necessary to generate embeddings applicable
                to a multitude of tasks. Existing strategies for the selection
                of the embedding dimension rely on performance maximization in
                downstream tasks. Here, we propose a principled method such that
                all structural information of a network is parsimoniously
                encoded. The method is validated on various embedding algorithms
                and a large corpus of real-world networks. The embedding
                dimension selected by our method in real-world networks suggest
                that efficient encoding in low-dimensional spaces is usually
                possible.
              </p>
              <!-- <ul class="actions">
                <li>
                  <a
                    href="https://www.nature.com/articles/s41467-021-23795-5.pdf"
                    class="button"
                  >
                    Download
                  </a>
                </li>
              </ul> -->
            </ul>
            <ul class="alt">
              <span class="image left"
                ><img src="./images/paper3.jpg" alt=""
              /></span>
              <a
                href="https://www.sciencedirect.com/science/article/pii/S0893608025003685"
                target="_blank"
                rel="noopener noreferrer"
              >
                <h3 style="text-decoration: underline">
                  MWTP: A heterogeneous multiplex representation learning
                  framework for link prediction of weak ties.
                  <em>Neural Networks.</em>
                </h3>
              </a>

              <h5>
                <p>Weiwei Gu, Linbi Lv, Gang Lu, Ruiqi Li</p>
              </h5>
              <p>
                Weak ties that bridge different communities are crucial for
                preserving global connectivity, enhancing resilience, and
                maintaining functionality and dynamics of complex networks,
                However, making accurate link predictions for weak ties remain
                challenging due to lacking of common neighbors. Most complex
                systems, such as transportation and social networks, comprise
                multiple types of interactions, which can be modeled by
                multiplex networks with each layer representing a different type
                of connection. Better utilizing information from other layers
                can mitigate the lack of information for predicting weak ties.
                Here, we propose a GNN-based representation learning framework
                for Multiplex Weak Tie Prediction (MWTP). It leverages both an
                intra-layer and an inter-layer aggregator to effectively learn
                and fuse information across different layers. The intra-layer
                one integrates features from multi-order neighbors, and the
                inter-layer aggregation exploits either logit regression or a
                more sophisticated semantic voting mechanism to compute
                nodal-level inter-layer attentions, leading to two variants of
                our framework, MWTP-logit, and MWTP-semantic. The former one is
                more efficient in implementation attribute to fewer parameters,
                while the latter one is slower but has stronger learning
                capabilities. Extensive experiments demonstrate that our MWTPs
                outperform eleven popular baselines for predicting both weak
                ties and all ties across diverse real-world multiplex networks.
                Additionally, MWTPs achieve good prediction performance with a
                relatively small training size.
              </p>
              <!-- <ul class="actions">
                <li>
                  <a href="" class="button"> Download </a>
                </li>
              </ul> -->
            </ul>
            <ul class="alt">
              <span class="image left"
                ><img src="./images/paper2.png" alt=""
              /></span>
              <a
                href="https://www.sciencedirect.com/science/article/abs/pii/S0378873318302272"
                target="_blank"
                rel="noopener noreferrer"
              >
                <h3 style="text-decoration: underline">
                  Exploring small-world network with an elite-clique: Bringing
                  embeddedness theory into the dynamic evolution of a venture
                  capital network. <em>Social Networks.</em>
                </h3>
              </a>

              <h5>
                <p>Weiwei Gu, Jar-der Luo, Jifan Liu</p>
              </h5>
              <p>
                This paper uses a network dynamics model to explain the
                formation of a small-world network with an elite-clique. This
                network is a small-world network with an elite-clique at its
                center in which elites are also the centers of many small
                groups. These leaders also act as bridges between different
                small groups. Network dynamics are an important research topic
                due to their ability to explain the evolution of network
                structures. In this paper, a Chinese Venture Capital (VC)
                network was coded from joint investments between VC firms and
                then analyzed to uncover its network properties and factors that
                influence its evolution. We first built a random graph model to
                control for factors such as network scale, network growth,
                investment frequency and syndication tendency. Then we added a
                partner-selection mechanism and used two theories to analyze the
                formation of network structure: relational embeddedness and
                structural embeddedness. After that, we ran simulations and
                compared the three models with the actual Chinese VC network. To
                do this we computed the elite-clique’s EI index, degree
                distribution, clustering coefficient distribution and motifs.
                Results show that adding embeddedness theories significantly
                improved the network dynamic model’s predictive power, and help
                us uncover the mechanisms that affect the formation of a
                small-world industrial network with an elite-clique at its
                center.
              </p>
              <!-- <ul class="actions">
                <li>
                  <a href="https://arxiv.org/pdf/1811.07471" class="button">
                    Download
                  </a>
                </li>
              </ul> -->
            </ul>

            <ul class="alt">
              <span class="image left"
                ><img src="./images/paperDis.webp" alt=""
              /></span>
              <a
                href="https://www.nature.com/articles/s41598-021-85826-x"
                target="_blank"
                rel="noopener noreferrer"
              >
                <h3 style="text-decoration: underline">
                  Discovering latent node Information by graph attention
                  network.<em>Scientific reports.</em>
                </h3>
              </a>

              <h5>
                <p>Weiwei Gu, Fei Gao, Xiaodan Lou, Jiang Zhang</p>
              </h5>
              <p>
                In this paper, we propose graph attention based network
                representation (GANR) which utilizes the graph attention
                architecture and takes graph structure as the supervised
                learning information. Compared with node classification based
                representations, GANR can be used to learn representation for
                any given graph. GANR is not only capable of learning high
                quality node representations that achieve a competitive
                performance on link prediction, network visualization and node
                classification but it can also extract meaningful attention
                weights that can be applied in node centrality measuring task.
                GANR can identify the leading venture capital investors,
                discover highly cited papers and find the most influential nodes
                in Susceptible Infected Recovered Model. We conclude that link
                structures in graphs are not limited on predicting linkage
                itself, it is capable of revealing latent node information in an
                unsupervised way once a appropriate learning algorithm, like
                GANR, is provided.
              </p>
              <!-- <ul class="actions">
                <li>
                  <a href="https://arxiv.org/pdf/1811.07471" class="button">
                    Download
                  </a>
                </li>
              </ul> -->
            </ul>
          </div>
        </section>
        <!-- One -->
        <!-- <section id="one" class="tiles">
          <article>
            <span class="image">
              <img src="images/pic01.jpg" alt="" />
            </span>
            <header class="major">
              <h3><a href="landing.html" class="link">Aliquam</a></h3>
              <p>Ipsum dolor sit amet</p>
            </header>
          </article>
          <article>
            <span class="image">
              <img src="images/pic02.jpg" alt="" />
            </span>
            <header class="major">
              <h3><a href="landing.html" class="link">Tempus</a></h3>
              <p>feugiat amet tempus</p>
            </header>
          </article>
          <article>
            <span class="image">
              <img src="images/pic03.jpg" alt="" />
            </span>
            <header class="major">
              <h3><a href="landing.html" class="link">Magna</a></h3>
              <p>Lorem etiam nullam</p>
            </header>
          </article>
          <article>
            <span class="image">
              <img src="images/pic04.jpg" alt="" />
            </span>
            <header class="major">
              <h3><a href="landing.html" class="link">Ipsum</a></h3>
              <p>Nisl sed aliquam</p>
            </header>
          </article>
          <article>
            <span class="image">
              <img src="images/pic05.jpg" alt="" />
            </span>
            <header class="major">
              <h3><a href="landing.html" class="link">Consequat</a></h3>
              <p>Ipsum dolor sit amet</p>
            </header>
          </article>
          <article>
            <span class="image">
              <img src="images/pic06.jpg" alt="" />
            </span>
            <header class="major">
              <h3><a href="landing.html" class="link">Etiam</a></h3>
              <p>Feugiat amet tempus</p>
            </header>
          </article>
        </section> -->
      </div>

      <!-- Contact -->
      <section>
        <div class="inner">
          <div class="row">
            <div class="col-6 col-12-medium">
              <div class="contact-method">
                <span class="icon solid alt fa-envelope"></span>
                <h3>Email</h3>
                <span>weiweigu#mail.buct.edu.cn</span>
              </div>
            </div>
            <div class="col-6 col-12-medium">
              <div class="contact-method">
                <span class="icon solid alt fa-home"></span>
                <h3>Address</h3>
                <span
                  >School of Information Science and Technology<br />
                  Beijing University of Chemical Technology, 100029<br />
                  Beijing, China</span
                >
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- Footer -->
      <footer id="footer">
        <div class="inner">
          <ul class="copyright">
            <li>&copy; Untitled</li>
            <li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
          </ul>
        </div>
      </footer>
    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>
  </body>
</html>
